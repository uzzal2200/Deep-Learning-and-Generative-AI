{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE9zoylNaH3t",
        "outputId": "602d96cb-3727-4175-b1e6-ad6194dc3a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: chod: command not found\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxK0RvwHafv3",
        "outputId": "9678bd5a-a2fe-4cc0-847e-a6fc577c3dbe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.2.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/jessicali9530/celeba-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1I25_f9aixm",
        "outputId": "e6f24ec6-2774-4da1-fc21-5abc9e9ffd4f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./celeba-dataset\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "dL5TOAAoa6G3"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CelebAdataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Get all image file paths from the directory\n",
        "        self.image_paths = [os.path.join(root_dir, img) for img in os.listdir(root_dir) if img.endswith('.jpg')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Apply the transform if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gh2JSJzubXOP"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations (resize, crop, convert to tensor, normalize)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),       # Resize images to 64x64\n",
        "    transforms.CenterCrop(64),    # Crop center to 64x64\n",
        "    transforms.ToTensor(),         # Convert images to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize to [-1, 1]\n",
        "\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "y3I0UlMNdVq3"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CelebA dataset\n",
        "dataset_path = '/content/celeba-dataset/img_align_celeba/img_align_celeba'\n",
        "dataset = CelebAdataset(root_dir=dataset_path, transform=transform)\n",
        "\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "# Check how many images are loaded\n",
        "print(f\"Number of images Loaded : {len(dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ofs3u2HeAJY",
        "outputId": "997b4b04-50e0-413c-c70a-e0ef5437656a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images Loaded : 202599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator classes\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100, img_channels=3):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, img_channels * 64 * 64),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), 3, 64, 64)  # Reshape to image format\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "TIHK-o4-fhXA"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, img_channels = 3):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.model=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(img_channels * 64 * 64, 1024),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(1024, 512),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(256, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, img):\n",
        "    return self.model(img)"
      ],
      "metadata": {
        "id": "m7VaIIgAh0Yo"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizers\n",
        "\n",
        "adversarial_loss = nn.BCELoss()\n",
        "generator = Generator(z_dim=100)\n",
        "discriminator = Discriminator()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "generator = generator.to(device)\n",
        "discriminator = discriminator.to(device)\n",
        "\n",
        "print(generator)\n",
        "print(f\" Discriminator parameter : {discriminator}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Si2ddK_i1tw",
        "outputId": "46624864-9359-4cd8-8d0a-2691d4b251b3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=1024, out_features=12288, bias=True)\n",
            "    (7): Tanh()\n",
            "  )\n",
            ")\n",
            " Discriminator parameter : Discriminator(\n",
            "  (model): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=12288, out_features=1024, bias=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (7): Linear(in_features=256, out_features=1, bias=True)\n",
            "    (8): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "\n",
        "def train(generator, discriminator, dataloader, epochs=5):\n",
        "  for epoch in range(epochs):\n",
        "    for i, imgs in enumerate(dataloader):\n",
        "      real_imgs = imgs.to(device)\n",
        "      batch_size = real_imgs.size(0)\n",
        "      valid = torch.ones(batch_size, 1).to(device)\n",
        "      fake = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "      # Train Discriminator\n",
        "\n",
        "      optimizer_D.zero_grad()\n",
        "      real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "      fake_loss = adversarial_loss(discriminator(generator(torch.randn(batch_size, 100).to(device)).detach()), fake)\n",
        "      d_loss = (real_loss + fake_loss )/ 2\n",
        "      d_loss.backward()\n",
        "      optimizer_D.step()\n",
        "\n",
        "      # Train the Generator\n",
        "\n",
        "      optimizer_G.zero_grad()\n",
        "      g_loss = adversarial_loss(discriminator(generator(torch.randn(batch_size, 100).to(device))), valid)\n",
        "      g_loss.backward()\n",
        "      optimizer_G.step()\n",
        "\n",
        "      if i % 50 == 0:\n",
        "       print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
        "\n",
        "   # Optionally, save generated images at each epoch\n",
        "  save_generated_images(generator, epoch, device)\n",
        "\n",
        "\n",
        "\n",
        "def save_generated_images(generator, epoch, device, num_images=16):\n",
        "    z = torch.randn(num_images, 100).to(device)\n",
        "    generated_imgs = generator(z).detach().cpu()\n",
        "    grid = torchvision.utils.make_grid(generated_imgs, nrow=4, normalize=True)\n",
        "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "    plt.title(f\"Epoch {epoch}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Start training\n",
        "train(generator, discriminator, dataloader, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzha7pAml63J",
        "outputId": "00c77e81-8189-4c3e-c38e-312f41cb06f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/10] [Batch 0/1583] [D loss: 0.6919902563095093] [G loss: 0.7207863926887512]\n",
            "[Epoch 0/10] [Batch 50/1583] [D loss: 0.2526938319206238] [G loss: 1.17840576171875]\n",
            "[Epoch 0/10] [Batch 100/1583] [D loss: 0.16395944356918335] [G loss: 1.9114402532577515]\n",
            "[Epoch 0/10] [Batch 150/1583] [D loss: 0.10349415242671967] [G loss: 2.0365304946899414]\n",
            "[Epoch 0/10] [Batch 200/1583] [D loss: 0.3843155801296234] [G loss: 1.8570724725723267]\n",
            "[Epoch 0/10] [Batch 250/1583] [D loss: 0.32253363728523254] [G loss: 0.9257451295852661]\n",
            "[Epoch 0/10] [Batch 300/1583] [D loss: 0.07519432157278061] [G loss: 2.762653350830078]\n",
            "[Epoch 0/10] [Batch 350/1583] [D loss: 0.1520053893327713] [G loss: 2.0360569953918457]\n",
            "[Epoch 0/10] [Batch 400/1583] [D loss: 0.37260374426841736] [G loss: 4.871382713317871]\n",
            "[Epoch 0/10] [Batch 450/1583] [D loss: 0.313314825296402] [G loss: 3.47910213470459]\n",
            "[Epoch 0/10] [Batch 500/1583] [D loss: 1.2905088663101196] [G loss: 0.4242846965789795]\n",
            "[Epoch 0/10] [Batch 550/1583] [D loss: 0.13431063294410706] [G loss: 2.0980191230773926]\n",
            "[Epoch 0/10] [Batch 600/1583] [D loss: 0.2418268471956253] [G loss: 0.8477210998535156]\n",
            "[Epoch 0/10] [Batch 650/1583] [D loss: 0.252034068107605] [G loss: 3.7264034748077393]\n",
            "[Epoch 0/10] [Batch 700/1583] [D loss: 0.21306411921977997] [G loss: 4.678238868713379]\n",
            "[Epoch 0/10] [Batch 750/1583] [D loss: 0.2890250086784363] [G loss: 2.2229676246643066]\n",
            "[Epoch 0/10] [Batch 800/1583] [D loss: 0.13727465271949768] [G loss: 2.723388433456421]\n",
            "[Epoch 0/10] [Batch 850/1583] [D loss: 0.2750372886657715] [G loss: 2.702162027359009]\n",
            "[Epoch 0/10] [Batch 900/1583] [D loss: 0.48311832547187805] [G loss: 0.5627498626708984]\n",
            "[Epoch 0/10] [Batch 950/1583] [D loss: 0.25036880373954773] [G loss: 2.2940762042999268]\n",
            "[Epoch 0/10] [Batch 1000/1583] [D loss: 0.24302376806735992] [G loss: 3.472771167755127]\n",
            "[Epoch 0/10] [Batch 1050/1583] [D loss: 0.9652295708656311] [G loss: 3.6797666549682617]\n",
            "[Epoch 0/10] [Batch 1100/1583] [D loss: 0.15032081305980682] [G loss: 2.647789478302002]\n",
            "[Epoch 0/10] [Batch 1150/1583] [D loss: 0.2473171502351761] [G loss: 2.002976417541504]\n",
            "[Epoch 0/10] [Batch 1200/1583] [D loss: 0.3860298991203308] [G loss: 2.948007822036743]\n",
            "[Epoch 0/10] [Batch 1250/1583] [D loss: 0.22840945422649384] [G loss: 1.9946544170379639]\n",
            "[Epoch 0/10] [Batch 1300/1583] [D loss: 0.3478897213935852] [G loss: 1.9042984247207642]\n",
            "[Epoch 0/10] [Batch 1350/1583] [D loss: 0.3664654493331909] [G loss: 2.447660446166992]\n",
            "[Epoch 0/10] [Batch 1400/1583] [D loss: 0.35032713413238525] [G loss: 3.3810534477233887]\n",
            "[Epoch 0/10] [Batch 1450/1583] [D loss: 0.29365774989128113] [G loss: 3.274299144744873]\n",
            "[Epoch 0/10] [Batch 1500/1583] [D loss: 0.5111023187637329] [G loss: 1.7201628684997559]\n",
            "[Epoch 0/10] [Batch 1550/1583] [D loss: 0.41715312004089355] [G loss: 3.114999771118164]\n",
            "[Epoch 1/10] [Batch 0/1583] [D loss: 0.5480222702026367] [G loss: 2.117980480194092]\n",
            "[Epoch 1/10] [Batch 50/1583] [D loss: 0.43465089797973633] [G loss: 3.988022804260254]\n",
            "[Epoch 1/10] [Batch 100/1583] [D loss: 0.3078041970729828] [G loss: 2.442202091217041]\n",
            "[Epoch 1/10] [Batch 150/1583] [D loss: 0.38248732686042786] [G loss: 2.162611484527588]\n",
            "[Epoch 1/10] [Batch 200/1583] [D loss: 0.4137125015258789] [G loss: 3.5448594093322754]\n",
            "[Epoch 1/10] [Batch 250/1583] [D loss: 0.41136616468429565] [G loss: 2.4004416465759277]\n",
            "[Epoch 1/10] [Batch 300/1583] [D loss: 0.39735060930252075] [G loss: 2.9885482788085938]\n",
            "[Epoch 1/10] [Batch 350/1583] [D loss: 0.2639264464378357] [G loss: 2.7381765842437744]\n",
            "[Epoch 1/10] [Batch 400/1583] [D loss: 0.34299436211586] [G loss: 2.4399633407592773]\n",
            "[Epoch 1/10] [Batch 450/1583] [D loss: 0.3040620684623718] [G loss: 2.140833616256714]\n",
            "[Epoch 1/10] [Batch 500/1583] [D loss: 0.5795146822929382] [G loss: 2.5999112129211426]\n",
            "[Epoch 1/10] [Batch 550/1583] [D loss: 0.2617512345314026] [G loss: 2.1690282821655273]\n",
            "[Epoch 1/10] [Batch 600/1583] [D loss: 0.29886293411254883] [G loss: 2.7171826362609863]\n",
            "[Epoch 1/10] [Batch 650/1583] [D loss: 0.3590242266654968] [G loss: 2.8292500972747803]\n",
            "[Epoch 1/10] [Batch 700/1583] [D loss: 0.3140379786491394] [G loss: 2.693781852722168]\n",
            "[Epoch 1/10] [Batch 750/1583] [D loss: 0.4370361268520355] [G loss: 2.0967941284179688]\n",
            "[Epoch 1/10] [Batch 800/1583] [D loss: 0.3725259304046631] [G loss: 2.5724706649780273]\n",
            "[Epoch 1/10] [Batch 850/1583] [D loss: 0.2612153887748718] [G loss: 2.658953905105591]\n"
          ]
        }
      ]
    }
  ]
}