{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eosshrgDJJuG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformations for CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)), # ResNet expects 224x224 images\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229, 0.224, 0.225])  # Normalization for pre-trained models\n",
        "])"
      ],
      "metadata": {
        "id": "bdQxm2buOqRE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading CIFAR-10 datasets\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WEtrk-wPkxL",
        "outputId": "ade1fa72-a068-4a37-8d9a-a11b41810300"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:14<00:00, 12.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "learning_rate = 0.001\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "kuvWPHHbQIzr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "# print(model.parameters())\n",
        "# Freeze the early layers (feature extractor)\n",
        "for param in model.parameters():\n",
        "  # print(param)\n",
        "  param.requires_grad = False\n",
        "\n",
        "# Replace the classifier layer (fully connected layer)\n",
        "num_ftrs = model.fc.in_features\n",
        "print(num_ftrs)\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg9wdFLLQ2zq",
        "outputId": "0e54fca6-c358-4322-d31b-f594f3fad3e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 207MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# move Model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "summary(model, (3, 224,224))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af4hN8CzW1VY",
        "outputId": "160bf2e5-492c-4cde-d6b5-a6ee0f13b1fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,181,642\n",
            "Trainable params: 5,130\n",
            "Non-trainable params: 11,176,512\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.65\n",
            "Estimated Total Size (MB): 106.01\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, test_loader, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_running_loss = 0\n",
        "        correct_train = 0\n",
        "\n",
        "        # Training loop\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Loss and accuracy calculation\n",
        "            total_running_loss += loss.item() * inputs.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct_train += preds.eq(labels).sum().item()\n",
        "\n",
        "        # Average loss and accuracy for the training set\n",
        "        avg_loss = total_running_loss / len(train_loader.dataset)\n",
        "        train_accuracy = correct_train / len(train_loader.dataset)\n",
        "        train_losses.append(avg_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        running_val_loss = 0\n",
        "        correct_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Loss and accuracy calculation\n",
        "                running_val_loss += loss.item() * inputs.size(0)\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                correct_val += preds.eq(labels).sum().item()\n",
        "\n",
        "        # Average loss and accuracy for the validation set\n",
        "        val_loss = running_val_loss / len(test_loader.dataset)\n",
        "        val_accuracy = correct_val / len(test_loader.dataset)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
        "        print(f\"Training    - Loss: {avg_loss:.4f}, Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "        print(f\"Validation  - Loss: {val_loss:.4f}, Accuracy: {val_accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "# Train and evaluate the model\n",
        "train_model(model, train_loader, test_loader, epochs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4GRqpqCdfrk",
        "outputId": "c7053e6a-3b68-485a-d546-e5d587ac741e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]\n",
            "Training    - Loss: 0.5332, Accuracy: 81.31%\n",
            "Validation  - Loss: 0.5683, Accuracy: 80.45%\n",
            "\n",
            "Epoch [2/5]\n",
            "Training    - Loss: 0.5128, Accuracy: 82.30%\n",
            "Validation  - Loss: 0.5637, Accuracy: 80.86%\n",
            "\n",
            "Epoch [3/5]\n",
            "Training    - Loss: 0.5095, Accuracy: 82.25%\n",
            "Validation  - Loss: 0.5620, Accuracy: 80.94%\n",
            "\n",
            "Epoch [4/5]\n",
            "Training    - Loss: 0.5074, Accuracy: 82.38%\n",
            "Validation  - Loss: 0.5709, Accuracy: 80.31%\n",
            "\n",
            "Epoch [5/5]\n",
            "Training    - Loss: 0.5066, Accuracy: 82.51%\n",
            "Validation  - Loss: 0.5793, Accuracy: 80.41%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate function\n",
        "def evaluate_model(model, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for input, label in test_loader:\n",
        "      input, label = input.to(device), label.to(device)\n",
        "      outputs = model(input)\n",
        "      loss = criterion(outputs, label)\n",
        "      test_loss += loss.item() * input.size(0)\n",
        "      pred = outputs.argmax(dim=1)\n",
        "      correct += pred.eq(label).sum().item()\n",
        "  avg_loss = test_loss / len(test_loader.dataset)\n",
        "  accuracy = correct/  len(test_loader.dataset)\n",
        "  print(f'Test Loss : {avg_loss: .4f}, Test Accuracy : {accuracy:.4f}')\n",
        "\n",
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb2qYHXHleW4",
        "outputId": "0d4257fb-19b5-4a02-e98f-375af7c2ebc7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss :  0.4823, Test Accuracy : 0.9021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "# Data transformations for CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)), # ResNet expects 224x224 images\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229, 0.224, 0.225])  # Normalization for pre-trained models\n",
        "])\n",
        "\n",
        "\n",
        "# Loading CIFAR-10 datasets\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "learning_rate = 0.001\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "# print(model)\n",
        "\n",
        "# Freeze the early layers (feature extractor)\n",
        "for param in model.parameters():\n",
        "  # print(param)\n",
        "  param.requires_grad = False\n",
        "\n",
        "# unfreeze the last two layers (layer4)\n",
        "for param in model.layer4.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "\n",
        "# Replace the classifier layer (fully connected layer)\n",
        "num_ftrs = model.fc.in_features\n",
        "print(num_ftrs)\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Print model summary\n",
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAv43sT9niS2",
        "outputId": "825646d5-6929-45bc-ffba-046376959b23"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,181,642\n",
            "Trainable params: 8,398,858\n",
            "Non-trainable params: 2,782,784\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.65\n",
            "Estimated Total Size (MB): 106.01\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer and Loss function\n",
        "# Include parameters of both the classifier and unfrozen layers\n",
        "optimizer = optim.Adam([\n",
        "    {'params': model.layer4.parameters()},\n",
        "    {'params': model.fc.parameters()}\n",
        "], lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_model (model, train_loader, epochs):\n",
        "  model.train()\n",
        "  for epoch in range(epochs):\n",
        "    total_running_loss = 0\n",
        "    correct = 0\n",
        "    for input, label in train_loader:\n",
        "      input,label = input.to(device), label.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(input)\n",
        "      loss = criterion(outputs,label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_running_loss += loss.item()  * input.size(0)\n",
        "      pred = outputs.argmax(dim=1)\n",
        "      correct += pred.eq(label).sum().item()\n",
        "\n",
        "    avg_loss = total_running_loss / len(train_loader.dataset)\n",
        "    accuracy = correct / len(train_loader.dataset)\n",
        "    print(f'Epoch [{epoch + 1} / {epochs}], Training Loss : {avg_loss:.4f}, Accuracy{accuracy:.4f}')\n",
        "\n",
        "\n",
        "train_model(model, train_loader, epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVQ9NXV4okX-",
        "outputId": "29005a4f-9d12-43fc-cbcf-97262b0d02dd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 5], Training Loss : 0.0561, Accuracy0.9811\n",
            "Epoch [2 / 5], Training Loss : 0.0351, Accuracy0.9883\n",
            "Epoch [3 / 5], Training Loss : 0.0312, Accuracy0.9897\n",
            "Epoch [4 / 5], Training Loss : 0.0231, Accuracy0.9920\n",
            "Epoch [5 / 5], Training Loss : 0.0290, Accuracy0.9900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for input,label in test_loader:\n",
        "      input, label = input.to(device), label.to(device)\n",
        "      output = model(input)\n",
        "      loss = criterion(output, label)\n",
        "      test_loss += loss.item() * input.size(0)\n",
        "      pred = output.argmax(dim=1)\n",
        "      correct += pred.eq(label).sum().item()\n",
        "\n",
        "  avg_loss = test_loss / len(test_loader.dataset)\n",
        "  accuracy = correct / len(test_loader.dataset)\n",
        "  print(f\"Test Loss: {avg_loss*100:.2f}, Test Accuracy: {accuracy*100:.2f}\")\n",
        "\n",
        "evaluate_model(model, test_loader)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otec1nDUtuu6",
        "outputId": "28bb17cb-1d7a-46c2-b4cc-c84b8ad03b61"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 48.23, Test Accuracy: 90.21\n"
          ]
        }
      ]
    }
  ]
}